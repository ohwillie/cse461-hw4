== P2Plickr

A.K.A. "HW4" for CSE461, WINTER 2010

Team Members: Rob Hanlon (rob@cs), Daniel Otero (oterod@cs)
Protocol: Elmo (AB)

== Answers to Questions

1. If all clients in the network are behaving properly, a log entry for a comment creation should never be received prior to the log entry for the associated photo's creation. This is because of the transitive relation between instances' log updates during anti-entropy. To get wind of the comment at first, any instance would have to have engaged in anti-entropy with the instance that authored the comment. This authoring instance, again assuming correct behavior, would have to have known about the creation of the comment's associated photo. A log entry for this photo's creation would have been in the authoring instance's logs, and such a log entry would be transmitted to any other instance during anti-entropy, along with the log entry for the comment's creation.

Will it happen in practice? Sure, if implementations are buggy. In our implementation, we test for this and, if we detect an anomaly like this, we abort the entire update from the offending instance. The fact that such a log entry could be transmitted from another instance suggests that the offending instance has somehow lost track of the overall ordering property. Including that instance's log entries poses serious risk to our own data consistency, and therefore we don't.

2. We have two components in our discovery system: a client and a server. Each runs in its own thread, and they share no direct communication. The server (the one we're interested in), listens for UDP broadcasts on the well-known port (30000). Whenever a broadcast is received, it is parsed and, if it matches the format of our protocol's discovery messages, we attempt to extract an IP/port for the other instance's anti-entropy server. We then consult a map (from IP => client) of running anti-entropy clients to ensure that we have no existing a-e client connected to the new IP. If no such mapping exists, we create one and spin up a new a-e client thread. When that client terminates, we remove the mapping of remote server's IP.

This is a simple way to ensure that, at any one time, we are engaging in anti-entropy exactly once with any single remote instance. While it does mean that we have a one-to-one mapping of anti-entropy connection to thread, we felt it was unnecessary to limit maximum threads via a fixed size thread pool and a blocking queue of unique, waiting connections. Having no inherent limit on simultaneous connections means that our implementation is vulnerable to the most basic DDoS attack; however, the protocol itself is vulnerable to programmatic spamming of updates, making any effort to ensure availability in spite of an adversary a waste of time. We thought it was equally unlikely that a legitimate
use case would include more than 50 (roughly the thread limit we might have used) machines on the same local network at once.

This approach has one additional benefit, and that is an attempt at enforcing some fairness. For each discoverable remote instance, we allow only one connection at a time, and all connections share our machine equally thanks to each running in its own equal-priority thread (this is not QUITE true in Ruby's thread model, but we'll let that slide). Though one remote instance could spam broadcasts more often than another, forcing unnecessary interaction and lowering our system's performance, there is no way for one instance to starve us of another instance's data.

3. We went the way of the black sheep and wrote a threaded anti-entropy system. Because we allow multiple client threads connected to multiple remote instance servers, we can fall prey to a race condition that single-threaded implementations cannot. Suppose one of our anti-entropy client threads generates a version vector and sends it to a remote server. In the mean time, a different client thread is receiving and applying updates of its own. The first client may now find that, because the vector it sent was out of date, its associated remote server may send us log entries that we already have. To avoid storing duplicate entries, we enforce a strict policy that no two log entries can have the same [OUID, TS] tuple. Any duplicate entries are discarded. While client-server interaction is not transactional, any modification of our database is, and therefore inconsistency is avoided.

4. There is a laundry list of things that we accept and/or recover from that are not specified in the protocol:

- If another instance's sent data (missing log entries) are not sorted, we sort them.
- If another instance's sent data includes duplicate log entries, we discard them.
- If another instance uses "proper" JSON and sends numbers as integer fields rather than as strings, we don't care.
- If the length prefix preceding a block of JSON sent over the wire is wrong, we don't care.
- We try to ignore any updates that break temporal ordering (e.g., question #1 above).
- Despite the protocol's specification that control strings are capitalized, accept valid control strings (e.g., "TYPE", "OUID") in any case (e.g., lower, upper, etc.).
- Despite the protocol's assertion that there will be one space between 'flickr' and <port_number> in the UDP broadcast message, we are both case- and whitespace-agnostic.
- Etc.

5. We followed most of the suggested implementation design. However, we did not use Java, nor did we follow the advice to keep things single threaded. Instead, we used Ruby and, for our UI, the Rails framework. We chose Ruby over Java for its terseness and ease of use, for the abundance of available libraries, and, well, because both of us are quite sick of Java. Using Rails had the added benefit that we could use the default Rails ORM layer: ActiveRecord. To make matters even easier, Rails now defaults to using sqlite3 unless otherwise specified. We used threading because it was, honestly, easier for us to write and think about. While this did mean that we needed to address a few issues that single-threaded implementations wouldn't (e.g., the issue above), a few extra checks here and there and a healthy dose of database-level transactions seemed to do the trick. sqlite locks the whole database on writes anyway, so as far as we can tell, no performance was really lost.

One bonus of using Rails was that we could write the UI as a single component: a dynamic web-app, instead of periodically generated static HTML. Addition and deletion of comments and photos can be performed through the same web interface that is used to view them.

6. This is guaranteed to work on the lab machines, but I can't vouch for any other boxes:
  a. Grab this shell script: http://cs.washington.edu/homes/rob/hanlon-otero-461-hw4.sh
    i. Inspect the shell script for correctness! If you're really paranoid, grab the .tar.gz file mentioned within that shell script and inspect it as well.
  b. Run that shell script (bash hanlon-otero-461-hw4.sh)! It'll grab our p2plickr app (as well as a self-contained Ruby environment), inflate it in /tmp, set up environment variables, and run the app.
  c. Turn on your speakers. Visit http://<hostname>:3000/. Have fun!

If you'd like to run everything again without having to grab the entire environment another time, then just run run.sh (bash run.sh), found in /tmp/hanlon-otero-461-hw4. Be forewarned! run.sh by default resets the current p2plickr database. If you don't want this to happen, then run run.sh with the --dont-reset flag.
  

7. Hasn't failed us yet (yes, we think it works).
